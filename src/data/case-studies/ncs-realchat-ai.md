---
title: 'Defining a way to help young people think critically when using generative AI'
description: 'Helping 15-17 year olds understand, examine and use generative AI in positive ways through enrichment activities.'
slug: 'ncs-realchat-ai'
customer: 'NCS and CAST'
categories: 'Discovery, Alpha, Beta, Live'
statistic: 'Helped 15-17 year olds understand and use generative AI.'
image: images/arc-case-study-image.png
problem: |
  The Alexandra Rose Charity needed to scale their service to reach more families. We worked with traders, families and the staff administering the scheme to understand their pain points and develop digital systems to help.

introduction: |

  The project was initiated by the [National Citizen Service](https://wearencs.com) (NCS) and the [Centre for the Acceleration of Social Technology](https://www.wearecast.org.uk) (CAST), who commissioned Neontribe to explore how to support young people (aged 15-17) in becoming thoughtful makers and critical users of generative AI. The focus was on developing a tool to be used outside the standard school curriculum. Collaborating closely with youth organisations and young people was fundamental to the project's co-creation approach, which followed the Design Council's "Double Diamond" model.

challenge: |
  The National Citizen Service and Centre for the Acceleration of Social Technology asked us:

    _“How might we support young people to become thoughtful makers and critical users of AI?”_

  We worked with 15 – 17 year olds from youth organisations [Beats Bus](https://beats-bus.co.uk), [The Politics Project](https://www.thepoliticsproject.org.uk) and [Warrington Youth Zone](https://warringtonyouthzone.org) to help provide an answer.

  Young people are the ones who will be living with this technology and this is about empowering them with the ability to embrace the opportunity AI offers safely and thoughtfully.

  ## What we did

   The project began with a discovery phase starting in November 2024. This involved research into existing work by organisations like Unicef and the National Literacy Trust. A key part of discovery was recruiting and conducting 12 one-on-one user research interviews with a diverse group of young people, facilitated by our partner youth organisations. Through these interviews, we learned that young people use AI for learning, creative projects, and emotional support. They value its benefits like saving time and simplifying information but are cautious about the risks of misinformation and over-reliance. Social media is a significant channel where they encounter AI content and are exposed to its dangers.

  Following discovery, we moved into defining potential solutions. We held workshops with 15 young people to generate ideas. These ideas were developed into two initial concepts: WhisperNet, a story-game exploring moral aspects of deep fakes, and ThinkAI, a tool to support questioning AI responses. We created prototypes using the tools [Twine](https://twinery.org) and [Figma](https://www.figma.com/login) respectively, and tested them with young people.

  Their feedback indicated a preference for ThinkAI because it offered more control and could be used multiple times. Young people wanted to learn about the issues with AI which are discussed less frequently, to gain new perspectives on the technology, and be guided in critical thinking about its use. We also identified areas for design improvement, such as simplifying complex interface text and ensuring the tool left users in a positive mental space, and clarified the intended use - by an individual or in a group context.

  Based on this feedback, we focused on developing ThinkAI. Technical development involved building the tool using Next.js, Vercel, and the OpenAI API. A core goal was to get generative AI to assess and critique its own responses. We engineered the system to have two personalities: a primary one generating responses and a second one critiquing them. Static content surrounding the AI output also highlights issues. Robust safeguards were built to manage unpredictable behaviour from the LLM and protect user privacy. The code was made publicly available under an open-source license. The tool was refined based on usability testing and feedback from young people and youth service partners, and renamed RealChatAI.

  It’s now live at [https://www.realchatai.org](https://www.realchatai.org)

  Ongoing work includes developing a lesson plan for youth workers to use alongside the tool, and seeking further funding for hosting, maintenance, and improvements.

    >"The co-creation model with young people at the driving seat was so important to me, the tech needs to be understood and shaped by those who will be using it." - _Jo Hutchinson, NCS_

result: |
  The project resulted in the delivery of [RealChatAI](https://www.realchatai.org). It provides young people with a way to interact with generative AI while surrounding its responses with content that puts its use in context and highlights potential issues such as bias or inaccuracy. It was shaped by extensive feedback from young people, addressing their desire to learn something new and gain fresh perspectives on AI issues. The tool is now being used by partner youth organisations, with plans for ongoing support and development.

conclusion: |
---
